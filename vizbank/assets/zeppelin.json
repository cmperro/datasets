{"paragraphs":[{"text":"%md\n\n# Data Engineer Notebook\n\n## Description\nThis set of scripts read data from raw csv data and saves it to hive managed tables.\n\n## Execution Steps\n\n* Step 1: Read raw location data, make sure that all locations have adresses and save to Hive managed table\n* Step 2: Read raw employee data and save to Hive managed table\n* Step 3: Read covid data and save to Hive managed table\n* Step 4: Read geocode data and save to Hive managed table\n* Step 5: Create hive materialized view for number of employees per location","user":"pvidal","dateUpdated":"2020-05-08T13:22:12+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":false,"tableHide":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1588603849822_-505237664","id":"20200504-145049_208312522","dateCreated":"2020-05-04T14:50:49+0000","dateStarted":"2020-05-06T01:00:58+0000","dateFinished":"2020-05-06T01:00:58+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:293"},{"text":"%md\n### Step 1: Read raw location data, make sure that all locations have adresses and save to Hive managed table","user":"pvidal","dateUpdated":"2020-05-08T13:22:13+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":false,"tableHide":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1588604230496_-86688390","id":"20200504-145710_1004098376","dateCreated":"2020-05-04T14:57:10+0000","dateStarted":"2020-05-06T11:36:52+0000","dateFinished":"2020-05-06T11:36:52+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:294"},{"text":"// Read raw location data\nval locationDf = spark.read.options(Map(\"inferSchema\"->\"true\",\"delimiter\"->\",\",\"header\"->\"true\")).csv(\"s3a://viz-cdp-bucket/raw/locations.csv\")\nlocationDf.printSchema()","user":"pvidal","dateUpdated":"2020-05-08T13:22:13+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala","tableHide":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<font color=\"red\">Previous livy session is expired, new livy session is created. Paragraphs that depend on this paragraph need to be re-executed!</font>"},{"type":"TEXT","data":"locationDf: org.apache.spark.sql.DataFrame = [LOCATION_ID: int, ADDRESS: string ... 29 more fields]\nroot\n |-- LOCATION_ID: integer (nullable = true)\n |-- ADDRESS: string (nullable = true)\n |-- BKCLASS: string (nullable = true)\n |-- CBSA: string (nullable = true)\n |-- CBSA_DIV: string (nullable = true)\n |-- CBSA_DIV_FLG: integer (nullable = true)\n |-- CBSA_DIV_NO: integer (nullable = true)\n |-- CBSA_METRO: integer (nullable = true)\n |-- CBSA_METRO_FLG: integer (nullable = true)\n |-- CBSA_METRO_NAME: string (nullable = true)\n |-- CBSA_MICRO_FLG: integer (nullable = true)\n |-- CBSA_NO: integer (nullable = true)\n |-- CERT: integer (nullable = true)\n |-- CITY: string (nullable = true)\n |-- COUNTY: string (nullable = true)\n |-- CSA: string (nullable = true)\n |-- CSA_FLG: integer (nullable = true)\n |-- CSA_NO: integer (nullable = true)\n |-- ESTYMD: string (nullable = true)\n |-- FI_UNINUM: integer (nullable = true)\n |-- MAINOFF: integer (nullable = true)\n |-- NAME: string (nullable = true)\n |-- OFFNAME: string (nullable = true)\n |-- OFFNUM: integer (nullable = true)\n |-- RUNDATE: string (nullable = true)\n |-- SERVTYPE: integer (nullable = true)\n |-- STALP: string (nullable = true)\n |-- STCNTY: integer (nullable = true)\n |-- STNAME: string (nullable = true)\n |-- UNINUM: integer (nullable = true)\n |-- ZIP: integer (nullable = true)"}]},"apps":[],"jobName":"paragraph_1588603278648_-1239611685","id":"20200504-144118_1021814178","dateCreated":"2020-05-04T14:41:18+0000","dateStarted":"2020-05-08T11:43:52+0000","dateFinished":"2020-05-08T11:44:41+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:295"},{"text":"// Make sure that all locations have adresses\nlocationDf.createOrReplaceTempView(\"location\")\n\nval allLocations = spark.sql(\"SELECT count(*) FROM location\")\n\nallLocations.show()","user":"pvidal","dateUpdated":"2020-05-08T13:22:14+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala","tableHide":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1588603542789_551685168","id":"20200504-144542_365748041","dateCreated":"2020-05-04T14:45:42+0000","dateStarted":"2020-05-06T01:01:47+0000","dateFinished":"2020-05-06T01:01:51+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:296"},{"text":"val allLocationsWithAddress = spark.sql(\"SELECT count(*) FROM location where ADDRESS is not null\")\n\nallLocationsWithAddress.show()","user":"pvidal","dateUpdated":"2020-05-08T13:22:15+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala","tableHide":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1588604304691_-1256049984","id":"20200504-145824_988488816","dateCreated":"2020-05-04T14:58:24+0000","dateStarted":"2020-05-06T01:01:52+0000","dateFinished":"2020-05-06T01:01:53+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:297"},{"text":"// Save to hive managed table\n\nimport com.hortonworks.hwc.HiveWarehouseSession\nimport com.hortonworks.hwc.HiveWarehouseSession._\nval hive = HiveWarehouseSession.session(spark).build()\nhive.showDatabases().show()","user":"pvidal","dateUpdated":"2020-05-08T13:22:15+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala","tableHide":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import com.hortonworks.hwc.HiveWarehouseSession\nimport com.hortonworks.hwc.HiveWarehouseSession._\nhive: com.hortonworks.spark.sql.hive.llap.HiveWarehouseSessionImpl = com.hortonworks.spark.sql.hive.llap.HiveWarehouseSessionImpl@6ffcbdd0\n+------------------+\n|     database_name|\n+------------------+\n|           default|\n|information_schema|\n|               sys|\n|     worldwidebank|\n+------------------+"}]},"apps":[],"jobName":"paragraph_1588604466020_1962721059","id":"20200504-150106_1157423807","dateCreated":"2020-05-04T15:01:06+0000","dateStarted":"2020-05-08T11:49:26+0000","dateFinished":"2020-05-08T11:49:29+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:298"},{"text":"hive.executeUpdate(\"CREATE DATABASE worldwidebank\");\nhive.setDatabase(\"worldwidebank\");\nlocationDf.write.format(\"com.hortonworks.spark.sql.hive.llap.HiveWarehouseConnector\").option(\"table\", \"locations\").save()","user":"pvidal","dateUpdated":"2020-05-08T13:22:16+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala","tableHide":true},"settings":{"params":{},"forms":{}},"results":{"code":"ERROR","msg":[{"type":"TEXT","data":"<console>:32: error: not found: value HIVE_WAREHOUSE_CONNECTOR\n       locationDf.write.format(HIVE_WAREHOUSE_CONNECTOR).option(\"table\", \"locations\").save()\n                               ^\n"}]},"apps":[],"jobName":"paragraph_1588725189457_-498576753","id":"20200506-003309_39288531","dateCreated":"2020-05-06T00:33:09+0000","dateStarted":"2020-05-08T11:56:26+0000","dateFinished":"2020-05-08T11:56:27+0000","status":"ERROR","progressUpdateIntervalMs":500,"$$hashKey":"object:299"},{"text":"val ds = hive.sql(\"select * from locations limit 10\")\nds.show()","user":"pvidal","dateUpdated":"2020-05-08T13:22:16+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala","tableHide":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1588726162284_-149553106","id":"20200506-004922_435064089","dateCreated":"2020-05-06T00:49:22+0000","dateStarted":"2020-05-06T01:02:09+0000","dateFinished":"2020-05-06T01:02:11+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:300"},{"text":"%md\n### Step 2: Read raw employee data and save to Hive managed table","user":"pvidal","dateUpdated":"2020-05-08T13:22:17+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":false,"tableHide":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1588726536734_-1489223061","id":"20200506-005536_624379466","dateCreated":"2020-05-06T00:55:36+0000","dateStarted":"2020-05-06T11:33:03+0000","dateFinished":"2020-05-06T11:33:03+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:301"},{"text":"val employeeDf = spark.read.options(Map(\"inferSchema\"->\"true\",\"delimiter\"->\",\",\"header\"->\"true\")).csv(\"s3a://viz-cdp-bucket/raw/employee_data.csv\")","user":"pvidal","dateUpdated":"2020-05-08T13:22:18+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala","tableHide":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1588764783228_2147014505","id":"20200506-113303_1528319006","dateCreated":"2020-05-06T11:33:03+0000","dateStarted":"2020-05-06T11:35:44+0000","dateFinished":"2020-05-06T11:36:24+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:302"},{"text":"import com.hortonworks.hwc.HiveWarehouseSession\nimport com.hortonworks.hwc.HiveWarehouseSession._\nval hive = HiveWarehouseSession.session(spark).build()\n\nhive.setDatabase(\"worldwidebank\");\nemployeeDf.write.format(\"com.hortonworks.spark.sql.hive.llap.HiveWarehouseConnector\").option(\"table\", \"employees\").save()","user":"pvidal","dateUpdated":"2020-05-08T13:22:18+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala","tableHide":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1588764944303_-1473430285","id":"20200506-113544_595223560","dateCreated":"2020-05-06T11:35:44+0000","dateStarted":"2020-05-06T11:36:34+0000","dateFinished":"2020-05-06T11:36:42+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:303"},{"text":"%md\n### Step 3: Read covid data and save to Hive managed table","user":"pvidal","dateUpdated":"2020-05-08T13:22:19+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":false,"tableHide":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1588764994102_483080664","id":"20200506-113634_1832908608","dateCreated":"2020-05-06T11:36:34+0000","dateStarted":"2020-05-06T11:37:04+0000","dateFinished":"2020-05-06T11:37:04+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:304"},{"text":"val covidDf = spark.read.options(Map(\"inferSchema\"->\"true\",\"delimiter\"->\",\",\"header\"->\"true\")).csv(\"s3a://viz-cdp-bucket/raw/covid_cases_04292020.csv\")\n\n","user":"pvidal","dateUpdated":"2020-05-08T13:22:19+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala","tableHide":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1588765023638_-741152170","id":"20200506-113703_1246022963","dateCreated":"2020-05-06T11:37:03+0000","dateStarted":"2020-05-06T11:38:44+0000","dateFinished":"2020-05-06T11:38:45+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:305"},{"text":"hive.setDatabase(\"worldwidebank\");\ncovidDf.write.format(\"com.hortonworks.spark.sql.hive.llap.HiveWarehouseConnector\").option(\"table\", \"covid_cases\").save()","user":"pvidal","dateUpdated":"2020-05-08T13:22:20+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala","tableHide":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1588765109156_2041718624","id":"20200506-113829_488202919","dateCreated":"2020-05-06T11:38:29+0000","dateStarted":"2020-05-06T11:38:58+0000","dateFinished":"2020-05-06T11:39:04+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:306"},{"text":"%md\n### Step 4: Read geocode data and save to Hive managed table","user":"pvidal","dateUpdated":"2020-05-08T13:22:20+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","tableHide":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1588795945423_-1204316943","id":"20200506-201225_1957883239","dateCreated":"2020-05-06T20:12:25+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:307"},{"text":"// Read raw location data\nval geoDf = spark.read.options(Map(\"inferSchema\"->\"true\",\"delimiter\"->\",\",\"header\"->\"true\")).csv(\"s3a://viz-cdp-bucket/raw/Geocodes_USA_with_Counties.csv\")\ngeoDf.printSchema()","user":"pvidal","dateUpdated":"2020-05-08T13:22:21+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala","tableHide":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1588765138273_649535201","id":"20200506-113858_1079907016","dateCreated":"2020-05-06T11:38:58+0000","dateStarted":"2020-05-06T20:10:06+0000","dateFinished":"2020-05-06T20:10:49+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:308"},{"text":"hive.setDatabase(\"worldwidebank\");\ngeoDf.write.format(\"com.hortonworks.spark.sql.hive.llap.HiveWarehouseConnector\").option(\"table\", \"us_geocodes_by_county\").save()","user":"pvidal","dateUpdated":"2020-05-08T13:22:21+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala","tableHide":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1588795805844_-2144733738","id":"20200506-201005_278241319","dateCreated":"2020-05-06T20:10:05+0000","dateStarted":"2020-05-06T20:11:08+0000","dateFinished":"2020-05-06T20:11:16+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:309"},{"user":"pvidal","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","tableHide":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1588942628442_1740730751","id":"20200508-125708_1774050238","dateCreated":"2020-05-08T12:57:08+0000","status":"READY","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:1725","text":"%md\n### Step 5: Create hive materialized view for number of employees per location","dateUpdated":"2020-05-08T13:22:22+0000"},{"user":"pvidal","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala","tableHide":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1588795852895_-1638034348","id":"20200506-201052_606234623","dateCreated":"2020-05-06T20:10:52+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:310","text":"hive.setDatabase(\"worldwidebank\");\n\nhive.executeUpdate(\"CREATE MATERIALIZED VIEW worldwidebank.employees_per_state as select locations.stname, count(*) as num_employees from employees, locations where employees.location=locations.location_id GROUP BY locations.stname ORDER BY num_employees\")","dateUpdated":"2020-05-08T13:37:07+0000","dateFinished":"2020-05-08T13:00:40+0000","dateStarted":"2020-05-08T13:00:39+0000","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"res6: Boolean = false"}]}},{"user":"pvidal","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala","tableHide":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1588942694794_-737859581","id":"20200508-125814_1651453476","dateCreated":"2020-05-08T12:58:14+0000","status":"READY","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:1810","dateUpdated":"2020-05-08T13:39:42+0000","text":"hive.executeUpdate(\"CREATE MATERIALIZED VIEW worldwidebank.employees_and_cases_per_state as (select locations.stname as state, employees_per_state.num_employees, sum(covid_cases.confirmed) as confirmed_cases from locations, employees_per_state,  covid_cases where employees_per_state.STNAME = locations.STNAME  and covid_cases.province_state = locations.stname  and employees_per_state.STNAME = covid_cases.province_state group by locations.stname, employees_per_state.num_employees)\")"}],"name":"Generate Dataset","id":"2F9ZDD323","noteParams":{},"noteForms":{},"angularObjects":{"md:shared_process":[],"livy:shared_process":[]},"config":{"isZeppelinNotebookCronEnable":false,"looknfeel":"default","personalizedMode":"false"},"info":{}}